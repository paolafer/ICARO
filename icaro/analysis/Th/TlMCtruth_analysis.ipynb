{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the analysis of the MC information truth of Tl source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import tables as tb\n",
    "import numpy  as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from   invisible_cities.database               import load_db\n",
    "\n",
    "import invisible_cities.reco.paolina_functions as plf\n",
    "from   invisible_cities.reco.dst_functions     import load_xy_corrections\n",
    "\n",
    "from   invisible_cities.io.dst_io              import load_dst\n",
    "from   invisible_cities.io.hits_io             import load_hits\n",
    "from   invisible_cities.io.hits_io             import load_hits_skipping_NN\n",
    "from invisible_cities.io.mchits_io             import load_mchits\n",
    "\n",
    "from   invisible_cities.types.ic_types         import xy\n",
    "from   invisible_cities.types.ic_types         import NN\n",
    "\n",
    "from   invisible_cities.evm.event_model        import Cluster, Hit\n",
    "\n",
    "import invisible_cities.core.fit_functions     as fitf\n",
    "\n",
    "from   invisible_cities.icaro.hst_functions    import hist\n",
    "from   invisible_cities.icaro.hst_functions    import gausstext\n",
    "\n",
    "from   invisible_cities.database               import load_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_NN_hits(hits_all,hits_nonNN):\n",
    "\n",
    "    # Iterate through the nonNN dictionary and update the energies including the NN hits from the \"all\" dictionary.\n",
    "    for (evt,hc) in hits_nonNN.items():\n",
    "        # Get the corresponding collection of all hits.\n",
    "        hc_all = hits_all[evt]            \n",
    "        # Add energy from all NN hits to hits in closest slice.\n",
    "        for h1 in hc_all.hits:\n",
    "            if(h1.Q == NN):\n",
    "                # Find the hits to which the energy will be added.\n",
    "                zdist_min = -1\n",
    "                h_add = []\n",
    "                for h2 in hc.hits:\n",
    "                    zdist = np.abs(h1.Z - h2.Z)\n",
    "                    if(zdist_min < 0 or zdist < zdist_min):\n",
    "                        zdist_min = zdist\n",
    "                        h_add = []\n",
    "                        h_add.append(h2)\n",
    "                    elif(zdist == zdist_min):\n",
    "                        h_add.append(h2)\n",
    "\n",
    "                # Add the energy.\n",
    "                hadd_etot = sum([ha.E for ha in h_add])\n",
    "                for ha in h_add:\n",
    "                    ha.energy += h1.E*(ha.E/hadd_etot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DetGeo = load_db.DetectorGeo()\n",
    "fwhmQbb = 0.006\n",
    "vox_size = np.array([15,15,15],dtype=np.int16)    # voxel size\n",
    "blob_radius = 21.   # blob radius in mm\n",
    "file_base_name = 'tl_pmaps_7bar_NEXT_v1_00_05_v0.9.2_20171011_krmc_tl'\n",
    "directory_name = '/home/Tl_v0.9.2'\n",
    "start = 0 ## analyzes first file 0\n",
    "numb = 5 ## number of files to be analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers for variables to be saved to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evt_energies = []\n",
    "trk_energies = []\n",
    "number_of_tracks = []\n",
    "number_of_voxels = []\n",
    "number_of_voxels_main = []\n",
    "length_main = []\n",
    "energy_main = []\n",
    "l_eblob1 = []; l_eblob2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop on the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
