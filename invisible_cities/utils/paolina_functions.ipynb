{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paolina functions\n",
    "For development and testing of IC-based Paolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "import abc\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from   collections import namedtuple\n",
    "from   invisible_cities.database import load_db\n",
    "from   invisible_cities.core.system_of_units_c import units\n",
    "\n",
    "import random\n",
    "import tables as tb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "\n",
    "NSIPM = 1792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Test events\n",
    "Read in using old PMap format, converted to a format to be passed to reconstruction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfile = \"/Users/jrenner/IFIC/jerenner/ICARO/invisible_cities/utils/hdf5_NEXT_NEW_se_1M_v0_08_07_0.h5\"\n",
    "erange_low = 0\n",
    "erange_high = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a 48x48 SiPM map\n",
    "# -- carried over from NEW_kr_diff_mc_train.ipynb\n",
    "def plot_test_event(l_X,l_Y,l_Q):\n",
    "    \"\"\"\n",
    "    Plots a SiPM map in the NEW Geometry\n",
    "    \"\"\"\n",
    "\n",
    "    # set up the figure\n",
    "    fig = plt.figure();\n",
    "    ax1 = fig.add_subplot(111);\n",
    "    fig.set_figheight(10.0)\n",
    "    fig.set_figwidth(10.0)\n",
    "    ax1.axis([-250, 250, -250, 250]);\n",
    "\n",
    "    # plot the SiPM pattern\n",
    "    for xx,yy,qq in zip(l_X,l_Y,l_Q):\n",
    "        r = Ellipse(xy=(xx, yy), width=2., height=2.);\n",
    "        r.set_facecolor('0');\n",
    "        r.set_alpha(qq);\n",
    "        ax1.add_artist(r);\n",
    "\n",
    "    # place a large blue circle for actual EL points\n",
    "    #if(hasattr(l_X0, \"__len__\")):\n",
    "    #    for xx,yy in zip(l_X0,l_Y0):\n",
    "    #        mrk = Ellipse(xy=(xx,yy), width=4., height=4.)\n",
    "    #        mrk.set_facecolor('b')\n",
    "    #        ax1.add_artist(mrk)\n",
    "    #else:\n",
    "    #    mrk = Ellipse(xy=(l_X0,l_Y0), width=4., height=4.)\n",
    "    #    mrk.set_facecolor('b')\n",
    "    #    ax1.add_artist(mrk)\n",
    "        \n",
    "    # place a large red circle for reconstructed points\n",
    "    #if(ept is not None):\n",
    "    #    xpt = ept[0]*fscale - fshift*fscale\n",
    "    #    ypt = ept[1]*fscale - fshift*fscale\n",
    "    #    mrk = Ellipse(xy=(xpt,ypt), width=2., height=2.);\n",
    "    #    mrk.set_facecolor('r');\n",
    "    #    ax1.add_artist(mrk);\n",
    "        \n",
    "    plt.xlabel(\"x (mm)\");\n",
    "    plt.ylabel(\"y (mm)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the SiPM (x,y) values\n",
    "DataSensor = load_db.DataSiPM()\n",
    "xs = DataSensor.X.values\n",
    "ys = DataSensor.Y.values\n",
    "\n",
    "# create (x,y) lists\n",
    "_sipm_x = np.zeros(NSIPM)\n",
    "_sipm_y = np.zeros(NSIPM)\n",
    "for ID, x, y in zip(range(NSIPM), xs, ys):\n",
    "    _sipm_x[ID] = x\n",
    "    _sipm_y[ID] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nevts = erange_high - erange_low\n",
    "\n",
    "# open the hdf5 file containing the PMaps.\n",
    "fname = \"{0}\".format(nfile)\n",
    "print(\"Opening file: {0}\".format(fname))\n",
    "fpmap = tb.open_file(fname,'r')\n",
    "pmaps = fpmap.root.PMaps.PMaps\n",
    "print(pmaps)\n",
    "\n",
    "# set up the lists\n",
    "tbl_T = []; tbl_E = [] \n",
    "tbl_X = []; tbl_Y = []; tbl_Q = []\n",
    "\n",
    "# loop over all events.\n",
    "rnum = 0                    # row number in table iteration\n",
    "ev = 0                      # processed event number (starts at 0 and runs to nevts-1)\n",
    "evtnum = pmaps[0]['event']  # event number from file\n",
    "while(rnum < pmaps.nrows and ev < nevts):\n",
    "\n",
    "    # Skip rows corresponding to event numbers outside of given range.\n",
    "    if((evtnum < erange_low or evtnum > erange_high) and not (erange_low < 0 or erange_high < 0)):\n",
    "        rnum += 1\n",
    "        if(rnum < pmaps.nrows):\n",
    "            evtnum = pmaps[rnum]['event']\n",
    "        continue\n",
    "\n",
    "    # Attempt to get all times, cathode energies, and anode values\n",
    "    #  for one event.\n",
    "    times = []\n",
    "    cathodes = []\n",
    "    anodes = []\n",
    "    while(rnum < pmaps.nrows and pmaps[rnum]['event'] == evtnum):\n",
    "        if(pmaps[rnum]['signal'] == b'S2'):\n",
    "            times.append(pmaps[rnum]['time'])\n",
    "            cathodes.append(pmaps[rnum]['cathode'])\n",
    "            anodes.append(pmaps[rnum]['anode'])\n",
    "        rnum += 1\n",
    "        \n",
    "    # convert to numpy arrays\n",
    "    anodes = np.array(anodes)\n",
    "    cathodes = np.array(cathodes)\n",
    "    times = np.array(times)\n",
    "\n",
    "    # if we had an S2 for this event, get the relevant information and add the event\n",
    "    if(len(times) > 0):\n",
    "        print(\"Had S2\")\n",
    "        \n",
    "        # store the energies and times of each projection\n",
    "        tbl_E.append(cathodes)\n",
    "        tbl_T.append(times)\n",
    "        \n",
    "        # create lists of (x,y,q) for each projection and store\n",
    "        evt_X = []; evt_Y = []; evt_Q = []\n",
    "        for aa in anodes:\n",
    "            ids = np.nonzero(aa)\n",
    "            evt_X.append(_sipm_x[ids])\n",
    "            evt_Y.append(_sipm_y[ids])\n",
    "            evt_Q.append(aa[ids])\n",
    "        tbl_X.append(evt_X)\n",
    "        tbl_Y.append(evt_Y)\n",
    "        tbl_Q.append(evt_Q)\n",
    "\n",
    "    # set to the next event\n",
    "    if(rnum < pmaps.nrows):\n",
    "        print(\"Processed event {0} with rnum {1} of {2} rows.\".format(evtnum, rnum, pmaps.nrows))\n",
    "        evtnum = pmaps[rnum]['event']\n",
    "        \n",
    "# convert to arrays\n",
    "tbl_X = np.array(tbl_X)\n",
    "tbl_Y = np.array(tbl_Y)\n",
    "tbl_Q = np.array(tbl_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot a test projection\n",
    "t_evt = 0; t_proj = 14\n",
    "t_X = tbl_X[t_evt][t_proj]; t_Y = tbl_Y[t_evt][t_proj]\n",
    "t_Q = tbl_Q[t_evt][t_proj]\n",
    "t_Q /= np.max(t_Q)\n",
    "\n",
    "plot_test_event(t_X,t_Y,t_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# Reconstruction\n",
    "Reconstruct 1 event (produce hit collection).  Later Paolina can be run on the hit collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# event to be reconstructed\n",
    "r_evt = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reconstruction objects (already defined)\n",
    "class Event:\n",
    "    def __init__(self):\n",
    "        self.evt  = -1\n",
    "        self.time = -1\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"{0}Event\\n{0}\".format(\"#\"*20 + \"\\n\")\n",
    "        for attr in self.__dict__:\n",
    "            s += \"{}: {}\\n\".format(attr, getattr(self, attr))\n",
    "        return s\n",
    "\n",
    "    def copy(self, other):\n",
    "        assert isinstance(other, Event)\n",
    "        for attr in other.__dict__:\n",
    "            setattr(self, attr, copy.deepcopy(getattr(other, attr)))\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def store(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "class Hit:\n",
    "    def __init__(self):\n",
    "        self.Npeak = -1\n",
    "        self.X     = -1e12\n",
    "        self.Y     = -1e12\n",
    "        self.R     = -1e12\n",
    "        self.Phi   = -1e12\n",
    "        self.Z     = -1\n",
    "        self.E     = -1\n",
    "        self.Q     = -1\n",
    "        self.Nsipm = -1\n",
    "\n",
    "class HitCollection(list, Event):\n",
    "    def __init__(self):\n",
    "        list .__init__(self)\n",
    "        Event.__init__(self)\n",
    "\n",
    "    def store(self, row):\n",
    "        for hit in self:\n",
    "            row[\"event\"] = self.evt\n",
    "            row[\"time\" ] = self.time\n",
    "\n",
    "            row[\"npeak\"] = hit.Npeak\n",
    "            row[\"X\"    ] = hit.X\n",
    "            row[\"Y\"    ] = hit.Y\n",
    "            row[\"Z\"    ] = hit.Z\n",
    "            row[\"R\"    ] = hit.R\n",
    "            row[\"Phi\"  ] = hit.Phi\n",
    "            row[\"Nsipm\"] = hit.Nsipm\n",
    "            row[\"Q\"    ] = hit.Q\n",
    "            row[\"E\"    ] = hit.E\n",
    "            row[\"Ecorr\"] = hit.Ecorr\n",
    "\n",
    "            row.append()\n",
    "\n",
    "# cluster named tuple (make the class using the namedtuple function)\n",
    "Cluster = namedtuple('Cluster', 'Q X Y Xrms Yrms Nsipm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from xy_algorithms.py (Gonzalo)\n",
    "def barycenter(xs, ys, qs, default=np.nan):\n",
    "    q    = np.sum(qs)\n",
    "    n    = len(qs)\n",
    "    x    = np.average(xs, weights=qs)         if n and q>0 else default\n",
    "    y    = np.average(ys, weights=qs)         if n and q>0 else default\n",
    "    xvar = np.sum(qs * (xs - x)**2) / (q - 1) if n and q>0 else default\n",
    "    yvar = np.sum(qs * (ys - y)**2) / (q - 1) if n and q>0 else default\n",
    "\n",
    "    c    = Cluster(q, x, y, xvar**0.5, yvar**0.5, n)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reco_algorithm(xs, ys, Qs, rmax=30*units.mm, T=3.5*units.pes):\n",
    "    \"\"\"\n",
    "    rmax is the maximum radius of a cluster\n",
    "    T is the threshold for local maxima (this kwarg may be unnecessary)\n",
    "    returns a list of Clusters\n",
    "    \"\"\"\n",
    "    c = []\n",
    "    xs = np.copy(xs)\n",
    "    ys = np.copy(ys)\n",
    "    qs = np.copy(Qs)\n",
    "\n",
    "    # While there are more local maxima\n",
    "    while len(qs) > 0:\n",
    "        i_max = np.argmax(qs)    # SiPM with largest Q\n",
    "        if qs[i_max] < T: break  # largest Q remaining is negligible\n",
    "\n",
    "        # get SiPMs within rmax of SiPM with largest Q\n",
    "        dists = np.sqrt((xs - xs[i_max]) ** 2 + (ys - ys[i_max]) ** 2)\n",
    "        cluster = np.where(dists < rmax)[0]\n",
    "\n",
    "        # get barycenter of this cluster\n",
    "        c.append(barycenter(xs[cluster], ys[cluster], qs[cluster]))\n",
    "\n",
    "        xs = np.delete(xs, cluster) # delete the SiPMs\n",
    "        ys = np.delete(ys, cluster) # contributing to\n",
    "        qs = np.delete(qs, cluster) # this cluster\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# different than Gonzalo's because we're using our test setup\n",
    "def compute_xy_position(xs,ys,Qs):\n",
    "    return reco_algorithm(xs, ys, Qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the energy across the clusters\n",
    "def split_energy(Es, clusters):\n",
    "    qtot = np.sum([cl.Q for cl in clusters])\n",
    "    return [(Es*cl.Q/qtot) for cl in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reconstruct the entire event\n",
    "e_X = tbl_X[r_evt]\n",
    "e_Y = tbl_Y[r_evt]\n",
    "e_T = tbl_T[r_evt]\n",
    "e_E = tbl_E[r_evt]\n",
    "e_Q = tbl_Q[r_evt]\n",
    "print(\"Total energy is {0}\".format(np.sum(e_E)))\n",
    "\n",
    "# set up the HitCollection\n",
    "hitc = HitCollection()\n",
    "hitc.evt   = r_evt\n",
    "hitc.time  = 0\n",
    "\n",
    "# iterate through all slices\n",
    "for Xs,Ys,Ts,Es,Qs in zip(e_X,e_Y,e_T,e_E,e_Q):\n",
    "    clusters = compute_xy_position(Xs,Ys,Qs)\n",
    "    es       = split_energy(Es, clusters)\n",
    "    z        = (Ts - 0.0) * 1000.0 / 1000.0  #(t_slice - S1t) * units.ns * self.drift_v\n",
    "    for c, e in zip(clusters, es):\n",
    "        hit       = Hit()\n",
    "        hit.Npeak = 0 #npeak\n",
    "        hit.X     = c.X\n",
    "        hit.Y     = c.Y\n",
    "        hit.R     = (c.X**2 + c.Y**2)**0.5\n",
    "        hit.Phi   = np.arctan2(c.Y, c.X)\n",
    "        hit.Z     = z\n",
    "        hit.Q     = c.Q\n",
    "        hit.E     = e\n",
    "        hit.Ecorr = e #correct_energy(e, c.X, c.Y, z)\n",
    "        hit.Nsipm = c.Nsipm\n",
    "        hitc.append(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "# Paolina algorithm\n",
    "At this point the hit collection for an event should be in the variable `hitc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables we need to set initially\n",
    "vol_min = np.array([-250, -250, 0])  # volume minimum (x,y,z)\n",
    "vol_max = np.array([250, 250, 800])  # volume maximum (x,y,z)\n",
    "vox_size = np.array([10, 10, 10])    # voxel size\n",
    "blob_radius = 15.                    # blob radius in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define voxel object\n",
    "class Voxel:\n",
    "    def __init__(self,ID,X,Y,Z,E,ix,iy,iz,size_x,size_y,size_z,tID):\n",
    "        self.ID     = ID\n",
    "        self.X      = X\n",
    "        self.Y      = Y\n",
    "        self.Z      = Z\n",
    "        self.E      = E\n",
    "        self.ix     = ix\n",
    "        self.iy     = iy\n",
    "        self.iz     = iz\n",
    "        self.size_x = size_x\n",
    "        self.size_y = size_y\n",
    "        self.size_z = size_z\n",
    "        self.iID    = tID\n",
    "#Voxel = namedtuple('Voxel', 'ID X Y Z E ix iy iz size_x size_y size_z tID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_voxels(hitc):\n",
    "    \"\"\"Builds a list of voxels from the specified hit collection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the size of the volume dimensions\n",
    "    vdim = vol_max - vol_min\n",
    "    \n",
    "    # create the voxel array\n",
    "    varr = np.zeros([vdim[0],vdim[1],vdim[2]])\n",
    "    \n",
    "    # add the energy of all hits to the voxels\n",
    "    for hh in hitc:\n",
    "        ivox = int((hh.X - vol_min[0]) / vox_size[0])\n",
    "        jvox = int((hh.Y - vol_min[1]) / vox_size[1])\n",
    "        kvox = int((hh.Z - vol_min[2]) / vox_size[2])\n",
    "        varr[ivox][jvox][kvox] += hh.E\n",
    "\n",
    "    # get lists of the nonzero x,y,z indices and E values\n",
    "    nzx,nzy,nzz = np.nonzero(varr)\n",
    "    nze = varr[np.nonzero(varr)]\n",
    "    \n",
    "    # create voxel objects\n",
    "    voxelc = []; vid = 0\n",
    "    for ix,iy,iz,ee in zip(nzx,nzy,nzz,nze):\n",
    "        voxelc.append(Voxel(vid,\n",
    "                            vol_min[0] + ix*vox_size[0],\n",
    "                            vol_min[1] + iy*vox_size[1],\n",
    "                            vol_min[2] + iz*vox_size[2],\n",
    "                            ee, ix, iy, iz,\n",
    "                            vox_size[0],vox_size[1],vox_size[2],\n",
    "                            -1))\n",
    "        #print(\"Added voxel {0},{1},{2} with {3}\".format(ix,iy,iz,ee))\n",
    "        vid += 1\n",
    "        \n",
    "    return voxelc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_adj_matrix(voxelc):\n",
    "    \"\"\"Creates the adjacency matrix.\n",
    "        -1         --> self\n",
    "        0          --> not a neighbor\n",
    "        (distance) --> voxels are neighbors    \n",
    "    \"\"\"\n",
    "    # use the voxels: determine neighboring voxels by face, edge, or corner connections\n",
    "    adj_mat = np.zeros([len(voxelc),len(voxelc)])\n",
    "\n",
    "    # iterate through all voxels, and for each one find the neighboring voxels\n",
    "    for vv1 in voxelc:\n",
    "        for vv2 in voxelc:\n",
    "            if(vv1.ix == vv2.ix and vv1.iy == vv2.iy and vv1.iz == vv2.iz):\n",
    "                adj_mat[vv1.ID][vv2.ID] = -1.\n",
    "            elif ((vv1.ix == vv2.ix+1 or vv1.ix == vv2.ix-1 or vv1.ix == vv2.ix) and \n",
    "                  (vv1.iy == vv2.iy+1 or vv1.iy == vv2.iy-1 or vv1.iy == vv2.iy) and \n",
    "                  (vv1.iz == vv2.iz+1 or vv1.iz == vv2.iz-1 or vv1.iz == vv2.iz)):\n",
    "                adj_mat[vv1.ID][vv2.ID] = np.sqrt((vv2.X-vv1.X)**2 + (vv2.Y-vv1.Y)**2 + (vv2.Z-vv1.Z)**2)\n",
    "        \n",
    "    return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_tracks(voxelc,adj_mat):\n",
    "    \"\"\"Constructs all independent tracks given the list of voxels and adjacency matrix.\n",
    "        Note: assumes the rows and columns of the adjacency matrix correspond\n",
    "            to the voxels in the order that they are placed in voxelc\n",
    "    \"\"\"\n",
    "    # add all voxels as nodes to a Graph\n",
    "    pgraph = nx.Graph()\n",
    "    pgraph.add_nodes_from(voxelc)\n",
    "        \n",
    "    # add edges connecting each node to its neighbor nodes based on the values in the adjacency matrix\n",
    "    for nA in voxelc:\n",
    "        for nB in voxelc:\n",
    "            ndist = adj_mat[nA.ID][nB.ID]\n",
    "            if(ndist > 0):\n",
    "                #print(\"-- Adding edge from {0} to {1} with weighting of {2}\".format(nA.ID,nB.ID,ndist))\n",
    "                pgraph.add_edge(nA,nB,weight=ndist)\n",
    "    \n",
    "    # find all independent tracks\n",
    "    trks = []\n",
    "    while(pgraph.number_of_nodes() > 0):\n",
    "        \n",
    "        # add all nodes with a path from node 0 to a single track\n",
    "        tnodes = []; tid = 0; gnodes = pgraph.nodes()\n",
    "        for nn in gnodes:\n",
    "            if(nx.has_path(pgraph,gnodes[0],nn)):\n",
    "                nn.tID = tid\n",
    "                tnodes.append(nn)\n",
    "                tid += 1\n",
    "        tgraph = nx.Graph()\n",
    "        tgraph.add_nodes_from(tnodes)\n",
    "        tgraph.add_weighted_edges_from(pgraph.edges(tnodes,data='weight'))\n",
    "        trks.append(tgraph)\n",
    "        \n",
    "        # remove these nodes from the original graph and start again\n",
    "        pgraph.remove_nodes_from(tnodes)\n",
    "        \n",
    "    # find the largest independent track\n",
    "    itmax = np.argmax([trk.number_of_nodes() for trk in trks])\n",
    "    #print(\"Found {0} tracks with max having {1} nodes\".format(len(trks),trks[itmax].number_of_nodes()))\n",
    "    \n",
    "    return (itmax,trks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_dist_mat(tgraph):\n",
    "    \"\"\"Calculates the distance matrix and longest shortest path.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the distance matrix\n",
    "    tvoxelc = tgraph.nodes()\n",
    "    dist_mat = np.zeros([len(tvoxelc),len(tvoxelc)])\n",
    "    dmax = -1.; v1max = None; v2max = None\n",
    "    \n",
    "    # compute the matrix, using only nodes in the specified track\n",
    "    for n1,vv1 in enumerate(tvoxelc):\n",
    "        for vv2 in tvoxelc[0:n1]:\n",
    "\n",
    "            # calculate the length of the shortest path between these two voxels\n",
    "            dist = nx.astar_path_length(tgraph,vv1,vv2)\n",
    "            #print(\"--- Adding dist of {0}\".format(dist))\n",
    "            dist_mat[vv1.tID][vv2.tID] = dist_mat[vv2.tID][vv1.tID] = dist\n",
    "            if(dist > dmax or dmax < 0):\n",
    "                dmax = dist; v1max = vv1; v2max = vv2\n",
    "                \n",
    "\n",
    "    # compute one longest shortest path\n",
    "    print(\"Longest shortest path is of length {0}\".format(dist_mat[v1max.tID][v2max.tID]))\n",
    "    spath = nx.astar_path(tgraph,v1max,v2max)\n",
    "    \n",
    "    return (dist_mat,spath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_blobs(tgraph,dist_mat,spath):\n",
    "    \"\"\"Construct the blobs.\n",
    "    \"\"\"\n",
    "    tvoxelc = tgraph.nodes()\n",
    "    Eblob1 = Eblob2 = 0\n",
    "    ext1 = spath[0]; ext2 = spath[-1]\n",
    "    #print(\"found ext1 {0} and ext2 {1}\".format(ext1,ext2))\n",
    "    \n",
    "    # add the energies of voxels within 1 blob radius of each extreme\n",
    "    for vv in tvoxelc:\n",
    "        dist1 = dist_mat[ext1.tID][vv.tID]\n",
    "        if(dist1 < blob_radius):\n",
    "            Eblob1 += vv.E\n",
    "        dist2 = dist_mat[ext2.tID][vv.tID]\n",
    "        if(dist2 < blob_radius):\n",
    "            Eblob2 += vv.E\n",
    "\n",
    "    return (Eblob1,Eblob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paolina(hitc):\n",
    "    \"\"\"The Paolina reconstruction algorithm.\n",
    "    \n",
    "        returns:\n",
    "        voxelc - a list of voxels in the track\n",
    "        spath - the longest shortest path (as a sequence of voxels) in the track\n",
    "        Eblob1 - the energy of the blob constructed about the first voxel in spath\n",
    "        Eblob2 - the energy of the blob constructed about the last voxel in spath\n",
    "    \"\"\"\n",
    "    voxelc = build_voxels(hitc)                                  # voxelize the event\n",
    "    adj_mat = calc_adj_matrix(voxelc)                            # calculate the adjacency matrix\n",
    "    itmax,trks = construct_tracks(voxelc,adj_mat)                # construct the tracks\n",
    "    dist_mat, spath = calc_dist_mat(trks[itmax])                 # calculate distance matrix and longest shortest path\n",
    "    Eblob1, Eblob2 = construct_blobs(trks[itmax],dist_mat,spath) # construct the blobs\n",
    "    \n",
    "    # return key quantities\n",
    "    return (voxelc,trks,itmax,spath,Eblob1,Eblob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform the Paolina algorithm\n",
    "voxelc,trks,itmax,spath,Eblob1,Eblob2 = paolina(hitc)\n",
    "print(\"Total of {0} tracks; longest contains {1} voxels\".format(len(trks),len(spath)))\n",
    "print(\"Blobs: {0} and {1}\".format(Eblob1,Eblob2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the voxelized tracks\n",
    "# 2D histogram\n",
    "fig = plt.figure(3);\n",
    "fig.set_figheight(5.0);\n",
    "fig.set_figwidth(20.0);\n",
    "\n",
    "varr_x = []; varr_y = []; varr_z = []; varr_c = []\n",
    "for vv in voxelc:\n",
    "    varr_x.append(vv.X)\n",
    "    varr_y.append(vv.Y)\n",
    "    varr_z.append(vv.Z)\n",
    "    varr_c.append(vv.E)\n",
    "\n",
    "vtrk_max = np.array([np.max(varr_x),np.max(varr_y),np.max(varr_z)])\n",
    "vtrk_min = np.array([np.min(varr_x),np.min(varr_y),np.min(varr_z)])\n",
    "\n",
    "# create the x-y projection\n",
    "ax1 = fig.add_subplot(131);\n",
    "hxy, xxy, yxy = np.histogram2d(varr_y, varr_x, weights=varr_c, normed=False, bins=(1.0*(vol_max[1]-vol_min[1])/vox_size[1], 1.0*(vol_max[0]-vol_min[0])/vox_size[0]), range=[[vol_min[1],vol_max[1]],[vol_min[0],vol_max[0]]])\n",
    "extent1 = [yxy[0], yxy[-1], xxy[0], xxy[-1]]\n",
    "sp1 = ax1.imshow(hxy, extent=extent1, interpolation='none', aspect='auto', origin='lower', cmap='jet')\n",
    "ax1.set_xlabel(\"x (mm)\")\n",
    "ax1.set_ylabel(\"y (mm)\")\n",
    "cbp1 = plt.colorbar(sp1)\n",
    "cbp1.set_label('Energy (Q)')\n",
    "\n",
    "# Create the y-z projection.\n",
    "ax2 = fig.add_subplot(132);\n",
    "hyz, xyz, yyz = np.histogram2d(varr_z, varr_y, weights=varr_c, normed=False, bins=(1.0*(vol_max[2]-vol_min[2])/vox_size[2], 1.0*(vol_max[1]-vol_min[1])/vox_size[1]), range=[[vol_min[2],vol_max[2]],[vol_min[1],vol_max[1]]])\n",
    "extent2 = [yyz[0], yyz[-1], xyz[0], xyz[-1]]\n",
    "sp2 = ax2.imshow(hyz, extent=extent2, interpolation='none', aspect='auto', origin='lower', cmap='jet')\n",
    "ax2.set_xlabel(\"y (mm)\")\n",
    "ax2.set_ylabel(\"z (mm)\")\n",
    "cbp2 = plt.colorbar(sp2);\n",
    "cbp2.set_label('Energy (Q)');\n",
    "\n",
    "# Create the x-z projection.\n",
    "ax3 = fig.add_subplot(133);\n",
    "hxz, xxz, yxz = np.histogram2d(varr_z, varr_x, weights=varr_c, normed=False, bins=(1.0*(vol_max[2]-vol_min[2])/vox_size[2], 1.0*(vol_max[0]-vol_min[0])/vox_size[0]), range=[[vol_min[2],vol_max[2]],[vol_min[0],vol_max[0]]])\n",
    "extent3 = [yxz[0], yxz[-1], xxz[0], xxz[-1]]\n",
    "sp3 = ax3.imshow(hxz, extent=extent3, interpolation='none', aspect='auto', origin='lower', cmap='jet')\n",
    "ax3.set_xlabel(\"x (mm)\")\n",
    "ax3.set_ylabel(\"z (mm)\")\n",
    "cbp3 = plt.colorbar(sp3);\n",
    "cbp3.set_label('Energy (Q)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
